import glob
import os
import pandas as pd
import itertools
basedir = ""


def get_prefixes(path,chip=4):
	return sorted(set(["_".join(os.path.basename(file)[::-1].split("_")[3:])[::-1] for file in glob.glob("%s/*.gz"%path)]))

def get_group_files(sample,dm):
	g = dm[dm["sample"] == sample]["group"].values[0]
#	print(g)
	return dm[dm["group"] == g]["sample"].values

	
	
# General config

minimap_index = "index/index/genomic/minimap2/hg19.mmi"



sample_pre = [s for s in get_prefixes("atacseq")]
sample_pre2 = list(sample_pre)
sample_dict = dict([(S,[s for s in glob.glob("atacseq/*.gz") if s.startswith("atacseq/%s"%S)]) for S in list(sample_pre2)])
samples_pre = pd.DataFrame(dict(samples=[s for s in get_prefixes("atacseq")])).set_index("samples",drop=False)
SAMPLE = samples_pre

designmatrix = pd.read_csv("./design_matrix_dec_2019_atacseq.csv")
#print(designmatrix.apply(lambda x:"%s.%04d.%s"%(x.cell_type,x.pid,x.cell_subset),1))
read_group = pd.Series(designmatrix.apply(lambda x:"%s.%04d.%s"%(x.cell_type,x.pid,x.cell_subset),1).values, index=designmatrix["sample"])
#print(read_group)
group = pd.Series(designmatrix["sample"].values, index=designmatrix["group"].values)

group_map = dict([(g,designmatrix.groupby("group").get_group(g)["sample"].values) for g in list(set(designmatrix["group"].values))])
groups = set(group.index.values)
group_dict = dict([(S,["align/initial/%s.bam"%s for s in get_group_files(S,designmatrix)]) for S in designmatrix["sample"].values])

rule all:
	input:
		peak=expand("peaks/genrich/{group}.narrowPeak", group=list(group_map.keys())),
		macs=designmatrix.apply(lambda x:"peaks/macs/%s/%s_peaks.narrowPeak"%(x["group"],x["sample"]),1).values,
		mapping=expand("tmp/{sample}_R{n}.fq.gz", sample=group_dict.keys(),group=group_dict.values(),n=[1,2])
	params:
		peaks=expand("peaks/{group}.peak", group=list(group_dict.keys()))

rule concatenate:
	input: 
		lambda wildcards: sample_dict[wildcards.sample]
	output:
		R1="concat/{sample}_R1.fq.gz",
		R2="concat/{sample}_R2.fq.gz"
	shell:
		"cat atacseq/{wildcards.sample}*R1*gz > {output.R1} && cat atacseq/{wildcards.sample}*R2*gz > {output.R2}"

rule trimming:
	input:
		R1=rules.concatenate.output.R1,
		R2=rules.concatenate.output.R2
	message: "Performing trimming for sample {input}"
	output:
		expand("trimmed/{{sample}}_val_{n}.fq.gz",n=[1,2])
	shell:
		"trim_galore --fastqc --gzip --paired -o trimmed --basename {wildcards.sample} {input.R1} {input.R2}"

rule mapping:
	input:
		rules.trimming.output
	params:
		index="index/genomic/minimap2/hg19.mmi",
		metrics="report/aligm/${sample}_metrics.txt",
		readgroup=lambda wildcards: "@RG\\tID:%s"%(read_group[wildcards.sample])
	message: "Mapping {wildcards.sample} of group {wildcards.group}"
	output:
		"align/initial/{group}/{sample}.bam"
	threads: 8
	shell:
		"set +o pipefail;minimap2 -t {threads} -a -x sr  -R \"{params.readgroup}\" {params.index} {input}| samtools view -bu | samtools sort -@ {threads} -o {output} && samtools index {output}"
	
rule dedup:
	input:
		IN=rules.mapping.output
	output:
		OUT="align/dedup/all/{group}/{sample}.dedup.bam",
		METRICS="report/dedup/{group}/{sample}_dup_metrics.txt"
	threads: 4
	shell: 
		"picard MarkDuplicates I={input.IN} O={output.OUT} VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true M={output.METRICS} && samtools index {output.OUT}"
rule flagstat:
	input:
		BAM="align/initial/{group}/{sample}.bam",
	output:
		"report/samples/{group}/{sample}_initial_flagstat.txt"
	shell:
		"samtools flagstat {input.BAM} > {output}"

rule mito:
	input:
		BAM_dedup="align/dedup/{group}/all/{sample}.dedup.bam"
	output:
		BAM_nomito="align/dedup/{group}/nomito/{sample}.nomito.dedup.bam",
		BAM_mito="align/dedup/{group}/mito/{sample}.nomito.dedup.bam"
	shell:
		"bedtools intersect -v {output.BAM_nonmito}"

#Genrich requires name sorted .....
rule namesort:
	input:
		"align/dedup/all/{group}/{sample}.dedup.bam"
	output:
		"align/dedup.namesorted/all/{group}/{sample}.dedup.namesorted.bam"
	threads: 4
	shell:
		"samtools sort -T /dev/shm -n {input} -@ {threads} | samtools view -b -o {output}"

rule peaks:
	input:
		lambda wildcards: expand("align/dedup.namesorted/all/{{group}}/{sample}.dedup.namesorted.bam",sample=group_map[wildcards.group])
	params: 
		blacklist="assets/hg19-blacklist.bed",
		files=lambda wildcards: ",".join(expand("align/dedup.namesorted/all/{group}/{sample}.dedup.namesorted.bam",sample=group_map[wildcards.group],group=wildcards.group))
	threads: 2 		
	output:
		narrowpeak="peaks/genrich/{group}.narrowPeak"
	shell:
		"Genrich -t {params.files} -o {output.narrowpeak} -j -r -E {params.blacklist}  -q 0.05 -e chrM"

rule macs:
	input:
		#"align/initial/{group}/{sample}.dedup.bam"
		rules.mapping.output
	params:
		sample=lambda wildcards: wildcards.sample,
		group=lambda wildcards: wildcards.group
	output:
		macs_narrowpeak="peaks/macs/{group}/{sample}_peaks.narrowPeak",
	shell:
		"macs2 callpeak -t {input} -f BAMPE --keep-dup all -g hs -n {params.sample} --nomodel --outdir peaks/macs/{params.group}/ -B --SPMR"

		


		
		

